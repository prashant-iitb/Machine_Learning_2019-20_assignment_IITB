{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# for data processing\n#encoding\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\n\n#To split training data to training and vaidatin data\nfrom sklearn.model_selection import train_test_split\n\n#Reading training data\ntrain_data = pd.read_csv('/kaggle/input/train.csv', header=0)\n#print(train_data)\nprint(\"Shape of dataframe is: {}\".format(train_data.shape))\ntrain_data_copy = train_data.copy()\n\n#Reading test data\ntest_data = pd.read_csv('/kaggle/input/test.csv', header=0)\ntest_data_copy = test_data.copy()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Delete unwanted columns\ntrain_data_copy = train_data.drop(['EmployeeCount','ID'],axis=1)\ntest_data_copy = test_data.drop(['EmployeeCount','ID'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#observe datatypes of different coloums\ntrain_data_copy.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It have (25-1) numeric data 7 string data.\nThese string data has to be changed"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Observe statistics of data\ntrain_data_copy.describe()\n# train_data_copy.hist(figsize=(20,20))\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of active and Ex employee\n#0-> Active\n#1-> Ex\ntrain_data_copy['Attrition'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#find % of active and Ex employee\nex_emp = train_data_copy[train_data_copy['Attrition'] == 1].shape[0]\nactive_emp = train_data_copy[train_data_copy['Attrition'] == 0].shape[0]\ntotal_emp=ex_emp + active_emp\n\nprint(\"Percentage of Current Employees is: {:.1f}% and of Ex-employees is: {:.1f}%\".format((ex_emp/total_emp)*100,(active_emp/total_emp)*100))\n#print(ex_emp)\n#print(active_emp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n    As shown on the chart above, we see this is an imbalanced class problem. Indeed, the percentage of Current Employees in our dataset is 83.3% and the percentage of Ex-employees is: 16.7%\n\n    Machine learning algorithms typically work best when the number of instances of each classes are roughly equal. We will have to address this target feature imbalance prior to implementing our Machine Learning algorithms.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's take a look at some of most significant correlations.\n#It is worth remembering that correlation coefficients only measure linear correlations.\n\n\n# Find correlations with the target and sort\ndf_HR_trans = train_data_copy.copy()\ndf_HR_trans['Target'] = df_HR_trans['Attrition']\ndf_HR_trans = df_HR_trans.drop('Attrition',axis=1)\n\ncorrelations = df_HR_trans.corr()['Target'].sort_values()\nprint('Most Positive Correlations: \\n', correlations.tail(6))\nprint('\\nMost Negative Correlations: \\n', correlations.head(6))\n\n# print(correlations)\n# correlations.shape\n#df_HR_trans.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Conclusion based on correlation\n1. The strongest positive correlations with the target features are: PerformanceRating, PercentageSaaryHike, MonthlyRate,NumCompaniesWorked, DistanceFromHome.\n2. The strongest negative correlations with the target features are: TotalWorkingYears, JobLevel, Age, MonthlyIncome, StockOptionLevel, YearsInCurrentRole.\n\nOther observations\n1. 52% Single employees \n2. About 16.2% of leavers after 1-year of work.\n3. 29% of leavers have distance from home of 1,2,3. Quite strange\n4. 66% of leavers travel rarely\n\n5. 55% of leaver work overtime.\n6. 27% of leavers are Laboratory Technician\n7. 38% of leavers are from life science\n8. 41% of leavers have worked for 1 company\n"},{"metadata":{},"cell_type":"markdown","source":"Machine Learning algorithms can typically only have numerical values as their predictor variables. Hence Label Encoding becomes necessary as they encode categorical labels with numerical values. To avoid introducing feature importance for categorical features with large numbers of unique values, we will use both Lable Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n# Create a label encoder object\n# Label Encoding will be used for columns with 2 or less unique values\n\nle = LabelEncoder()\nle_count = 0\nfor col in train_data_copy.columns[1:]:\n    if train_data_copy[col].dtype == 'object':\n        if len(list(train_data_copy[col].unique())) <= 2:\n            le.fit(train_data_copy[col])\n            train_data_copy[col] = le.transform(train_data_copy[col])\n            le_count = le_count + 1\nprint('{} columns were label encoded.'.format(le_count))\n\n\n\n# convert rest of categorical variable into dummy\ntrain_data_copy = pd.get_dummies(train_data_copy, drop_first=True)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data_copy.shape)\ntrain_data_copy.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Scaling**\n\nFeature Scaling using MinMaxScaler essentially shrinks the range such that the range is now between 0 and n. Machine Learning algorithms perform better when input numerical variables fall within a similar scale. In this case, we are scaling between 0 and 5."},{"metadata":{"trusted":true},"cell_type":"code","source":"# import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 5))\nHR_col = list(train_data_copy.columns)\nHR_col.remove('Attrition')\nfor col in HR_col:\n    train_data_copy[col] = train_data_copy[col].astype(float)\n    train_data_copy[[col]] = scaler.fit_transform(train_data_copy[[col]])\ntrain_data_copy['Attrition'] = pd.to_numeric(train_data_copy['Attrition'], downcast='float')\ntrain_data_copy.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Splitting data into training and testing sets**\n\nPrior to implementating or applying any Machine Learning algorithms, we must decouple training and testing datasets from our master dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"# assign the target to a new dataframe and convert it to a numerical feature\n#df_target = df_HR[['Attrition']].copy()\ntarget = train_data_copy['Attrition'].copy()\ntrain_data_copy = train_data_copy.drop(['Attrition'],axis=1)\ntrain_data_copy.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since we have class imbalance (i.e. more employees with turnover=0 than turnover=1)\n# let's use stratify=y to maintain the same ratio as in the training dataset when splitting the dataset\n#20% of train as we test data_set contain 1 i.e ex-employee \nX_train, X_test, y_train, y_test = train_test_split(train_data_copy, target, test_size=0.25, random_state=7, stratify=target)\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Algorithms**\n\nThe algorithms considered are: Logistic Regression, Random Forest, SVM."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Common sklearn Model Helpers\nfrom sklearn import model_selection\n# sklearn modules for preprocessing\nfrom sklearn.model_selection import KFold\n# Libraries for data modelling\n# from sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Logistic Regression**\n\nLet's take a closer look at using the Logistic Regression algorithm. we will use 10 fold Cross-Validation to train our Logistic Regression Model and estimate its AUC score.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelCV = LogisticRegression(solver='liblinear',random_state=7)\nmodelCV.fit(X_train,y_train)\n# modelCV.fit(train_data_copy,target)\nfrom sklearn.metrics import accuracy_score\nprint('Logistic regression accuracy: {:.3f}'.format(accuracy_score(y_test, modelCV.predict(X_test))))\n\n# from sklearn.metrics import classification_report\n# print(classification_report(y_test, modelCV.predict(X_test)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logistic Regression fine_tuned\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = {'C': np.arange(1e-03, 2, 0.01)} # hyper-parameter list to fine-tune\n\nlog_gs = GridSearchCV(LogisticRegression(solver='liblinear',\n                                         random_state=7),\n                      iid=True,\n                      return_train_score=True,\n                      param_grid=param_grid,\n                      scoring='roc_auc',\n                      cv=10)\n\nlog_grid = log_gs.fit(X_train, y_train)\nlog_opt = log_grid.best_estimator_\nresults = log_gs.cv_results_\n\n\nprint('Logistic regression accuracy: {:.3f}'.format(accuracy_score(y_test, log_opt.predict(X_test))))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# kfold = model_selection.KFold(n_splits=10, random_state=7)\nrf = RandomForestClassifier()\n# scoring = 'accuracy'\n# results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n# print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))\n\nrf.fit(X_train, y_train)\n\nprint('Random Forest Accuracy: {:.3f}'.format(accuracy_score(y_test, rf.predict(X_test))))\n# from sklearn.metrics import classification_report\n# print(classification_report(y_test, rf.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Support Vector Machine**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train, y_train)\nprint('Support vector machine accuracy: {:.3f}'.format(accuracy_score(y_test, svc.predict(X_test))))\n\n# from sklearn.metrics import classification_report\n# print(classification_report(y_test, svc.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test data signal processing\n\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\n# Create a label encoder object\n# Label Encoding will be used for columns with 2 or less unique values\n\nle = LabelEncoder()\nle_count = 0\nfor col in test_data_copy.columns[1:]:\n    if test_data_copy[col].dtype == 'object':\n        if len(list(test_data_copy[col].unique())) <= 2:\n            le.fit(test_data_copy[col])\n            test_data_copy[col] = le.transform(test_data_copy[col])\n            le_count = le_count + 1\n\n\n\n# convert rest of categorical variable into dummy\ntest_data_copy = pd.get_dummies(test_data_copy, drop_first=True)\n# test_data_copy.head()\n\n\n\n# import MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 5))\nHR_col = list(test_data_copy.columns)\n# HR_col.remove('Attrition') commented bec since in test no attrition\nfor col in HR_col:\n    test_data_copy[col] = test_data_copy[col].astype(float)\n    test_data_copy[[col]] = scaler.fit_transform(test_data_copy[[col]])\ntest_data_copy.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Evauation on test data\n\n#1) Using Logistic Regression Model\nmodelCV.fit(X_train,y_train)\nans=modelCV.predict(test_data_copy)\n#Saving prediction in csv\ntest_ID = test_data['ID']\nsubmission = pd.DataFrame(ans,columns=['Attrition'])\nsubmission=submission.astype(int)\n\noutput_file = pd.concat([test_ID,submission], axis=1, sort=False)\noutput_file.to_csv('183079037_LR.csv', index=False)\n\n#2) Using Logistic Regression Model, fine tune\nlog_opt.fit(X_train,y_train)\nans=log_opt.predict(test_data_copy)\n#Saving prediction in csv\ntest_ID = test_data['ID']\nsubmission = pd.DataFrame(ans,columns=['Attrition'])\nsubmission=submission.astype(int)\n\noutput_file = pd.concat([test_ID,submission], axis=1, sort=False)\noutput_file.to_csv('183079037_LR_finetune.csv', index=False)\n\n#3) Using Random Forest\nrf.fit(X_train,y_train)\nans=rf.predict(test_data_copy)\n#Saving prediction in csv\ntest_ID = test_data['ID']\nsubmission = pd.DataFrame(ans,columns=['Attrition'])\nsubmission=submission.astype(int)\n\noutput_file = pd.concat([test_ID,submission], axis=1, sort=False)\noutput_file.to_csv('183079037_RF.csv', index=False)\n\n#4) Using Support Vector Machine\nsvc.fit(X_train,y_train)\nans=svc.predict(test_data_copy)\n#Saving prediction in csv\ntest_ID = test_data['ID']\nsubmission = pd.DataFrame(ans,columns=['Attrition'])\nsubmission=submission.astype(int)\n\noutput_file = pd.concat([test_ID,submission], axis=1, sort=False)\noutput_file.to_csv('183079037_SVM.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import auc, roc_auc_score, roc_curve, recall_score, log_loss\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score, make_scorer\n\n\n#modelCV\nmodelCV.fit(X_train, y_train) # fit optimised model to the training data\nprobs = modelCV.predict_proba(X_test) # predict probabilities\nprobs = probs[:, 1] # we will only keep probabilities associated with the employee leaving\nlogit_roc_auc = roc_auc_score(y_test, probs) # calculate AUC score using test dataset\nprint('AUC score: %.3f' % logit_roc_auc)\n\n#finetune\nlog_opt.fit(X_train, y_train) # fit optimised model to the training data\nprobs = log_opt.predict_proba(X_test) # predict probabilities\nprobs = probs[:, 1] # we will only keep probabilities associated with the employee leaving\nlogit_roc_auc_fine = roc_auc_score(y_test, probs) # calculate AUC score using test dataset\nprint('AUC score: %.3f' % logit_roc_auc_fine)\n\n\n# Create ROC Graph\nfrom sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, modelCV.predict_proba(X_test)[:,1])\nfine_fpr, fine_tpr, fine_thresholds = roc_curve(y_test, log_opt.predict_proba(X_test)[:,1])\n\nplt.figure(figsize=(14, 6))\n\n# Plot Logistic Regression ROC\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n# Plot fine tune\nplt.plot(fine_fpr, fine_tpr, label='Logistic Regression fine tune(area = %0.2f)' % logit_roc_auc_fine)\n\n\n\n\n# Plot Base Rate ROC\nplt.plot([0,1], [0,1],label='Base Rate' 'k--')\n\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Graph')\nplt.legend(loc=\"lower right\")\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}